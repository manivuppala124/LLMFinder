# LLMMatch ‚Äî Intelligent LLM Recommendation System

<div align="center">

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.115+-00a393.svg)
![React](https://img.shields.io/badge/React-18.3+-61dafb.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

**Find Your Perfect LLM in Seconds**

An intelligent recommendation system that automatically identifies the most suitable Large Language Model based on your specific requirements ‚Äî task type, budget, latency, context length, and deployment constraints.

[Features](#-features) ‚Ä¢ [Demo](#-demo) ‚Ä¢ [Quick Start](#-quick-start) ‚Ä¢ [Architecture](#-architecture) ‚Ä¢ [API Docs](#-api-documentation) ‚Ä¢ [Contributing](#-contributing)

</div>

---

## üìã Table of Contents

- [About](#-about)
- [Features](#-features)
- [Tech Stack](#-tech-stack)
- [Quick Start](#-quick-start)
- [Project Structure](#-project-structure)
- [API Documentation](#-api-documentation)
- [How It Works](#-how-it-works)
- [Dataset](#-dataset)
- [Testing](#-testing)
- [Deployment](#-deployment)
- [Contributing](#-contributing)
- [License](#-license)
- [Team](#-team)

---

## üéØ About

**LLMMatch** solves a critical problem in modern AI development: **choosing the right LLM from 200+ available models**. 

With the explosion of LLMs (GPT-4, Claude, Gemini, Llama, Mistral, etc.), selecting the optimal model for a specific use case has become increasingly complex. Developers and teams waste valuable time researching costs, performance benchmarks, and capabilities across scattered documentation.

**LLMMatch** provides an intelligent, automated solution that:
- ‚úÖ Takes your requirements as input (task, budget, latency, context, deployment)
- ‚úÖ Scores and ranks all available LLMs using a weighted algorithm
- ‚úÖ Returns top 3 recommendations with detailed explanations
- ‚úÖ Optionally enhances predictions using machine learning

---

## ‚ú® Features

### üîç **Intelligent Recommendation Engine**
- Multi-parameter scoring algorithm with priority-based weighting
- Considers task type, cost constraints, latency requirements, context window, and deployment preferences
- Returns top 3 LLMs ranked by suitability score (0-100)

### üí¨ **Explainable AI**
- Every recommendation includes natural language explanation
- Transparent reasoning: "GPT-4o-mini scores 92/100 because it fits your $5 budget ($0.15 actual), excels at code tasks (0.88 score), supports 128k context..."
- Cost, speed, and capability breakdowns

### üìä **Comprehensive Knowledge Base**
- 20+ LLM models from major providers (OpenAI, Anthropic, Google, Meta, Mistral, etc.)
- Real-time pricing data per 1M tokens
- Context window sizes (4k ‚Üí 2M tokens)
- Latency classifications (realtime / moderate / batch)
- Task-specific capability scores

### ü§ñ **Optional ML Enhancement**
- RandomForest classifier trained on synthetic requirement patterns
- Enhances prediction accuracy for complex scenarios
- Fallback to rule-based scoring for reliability

### üé® **Modern UI/UX**
- Multi-step wizard for requirement collection
- Interactive result cards with animated score bars
- Browse all models in sortable, filterable table
- Fully responsive design

---

## üõ†Ô∏è Tech Stack

### **Backend**
- **Framework:** FastAPI (Python 3.10+)
- **Server:** Uvicorn (ASGI)
- **Validation:** Pydantic v2
- **ML:** scikit-learn (RandomForestClassifier)
- **Data:** pandas, numpy
- **Persistence:** joblib

### **Frontend**
- **Framework:** React 18.3+
- **Build Tool:** Vite
- **Styling:** CSS Modules (no Tailwind)
- **HTTP Client:** Axios
- **Routing:** React Router v6

### **Data Layer**
- **Storage:** JSON knowledge base
- **No external database required**

---

## üöÄ Quick Start

### Prerequisites
```bash
# Required
- Python 3.10+
- Node.js 18+ & npm
- Git
```

### Installation

#### 1Ô∏è‚É£ Clone the Repository
```bash
git clone https://github.com/manivuppala124/LLMFinder.git
cd LLMFinder
```

#### 2Ô∏è‚É£ Backend Setup
```bash
cd backend

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run FastAPI server
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

Backend will be available at: `http://localhost:8000`  
Interactive API docs: `http://localhost:8000/docs`

#### 3Ô∏è‚É£ Frontend Setup
```bash
cd ../frontend

# Install dependencies
npm install

# Start development server
npm run dev
```

Frontend will be available at: `http://localhost:5173`

---

## üìÇ Project Structure

```
LLMFinder/
‚îú‚îÄ‚îÄ backend/                    # FastAPI backend
‚îÇ   ‚îú‚îÄ‚îÄ main.py                # FastAPI app + routes
‚îÇ   ‚îú‚îÄ‚îÄ models.py              # Pydantic schemas
‚îÇ   ‚îú‚îÄ‚îÄ scorer.py              # Weighted scoring engine
‚îÇ   ‚îú‚îÄ‚îÄ ml_model.py            # RandomForest ML model
‚îÇ   ‚îú‚îÄ‚îÄ knowledge_base.json    # LLM characteristics data
‚îÇ   ‚îú‚îÄ‚îÄ trained_model.pkl      # Saved ML model (auto-generated)
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îÇ
‚îú‚îÄ‚îÄ frontend/                   # React frontend
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/        # Reusable components
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Navbar.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ModelCard.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ScoreBar.jsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/             # Route pages
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Home.jsx       # Landing page
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Form.jsx       # Multi-step wizard
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Results.jsx    # Recommendation results
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Models.jsx     # All models table
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ styles/            # CSS modules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.js         # Axios instance
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.jsx
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ vite.config.js
‚îÇ
‚îú‚îÄ‚îÄ tests/                      # Test suite
‚îú‚îÄ‚îÄ test_reports/               # Test results
‚îú‚îÄ‚îÄ memory/                     # Session persistence
‚îú‚îÄ‚îÄ design_guidelines.json      # UI/UX design system
‚îî‚îÄ‚îÄ README.md                   # This file
```

---

## üì° API Documentation

### **Base URL:** `http://localhost:8000`

### Endpoints

#### 1. **POST** `/api/recommend`
Get top 3 LLM recommendations based on requirements.

**Request Body:**
```json
{
  "task_type": "code",
  "budget_per_1m": 5.0,
  "latency": "moderate",
  "context_length": 128000,
  "deployment": "cloud",
  "priority": "balanced"
}
```

**Response:**
```json
{
  "top_model": {
    "name": "GPT-4o-mini",
    "provider": "OpenAI",
    "score": 92.0,
    "cost_score": 95.0,
    "speed_score": 88.0,
    "capability_score": 92.0,
    "explanation": "GPT-4o-mini scores 92/100. It fits your $5 budget ($0.15 actual)...",
    "tags": ["gpt", "fast", "affordable"],
    "link": "https://openai.com/api/pricing"
  },
  "alternatives": [
    { /* Alternative 1 */ },
    { /* Alternative 2 */ }
  ],
  "method_used": "scoring"
}
```

#### 2. **GET** `/api/models`
Retrieve all available LLMs from knowledge base.

**Response:**
```json
[
  {
    "name": "GPT-4o",
    "provider": "OpenAI",
    "cost_input_per_1m": 2.5,
    "cost_output_per_1m": 10.0,
    "context_window": 128000,
    "latency_class": "realtime",
    "deployment": ["cloud"],
    "task_scores": {
      "code": 0.95,
      "chat": 0.92,
      "summarize": 0.88,
      "analysis": 0.94,
      "translation": 0.85,
      "rag": 0.90
    },
    "tags": ["gpt", "multimodal", "premium"],
    "link": "https://openai.com/api/pricing"
  }
  // ... more models
]
```

#### 3. **GET** `/api/health`
Health check endpoint.

**Response:**
```json
{
  "status": "ok"
}
```

---

## ‚öôÔ∏è How It Works

### Workflow Overview

```
User Fills Form ‚Üí Frontend Sends Request ‚Üí Backend Scores All LLMs ‚Üí Returns Top 3
```

### Scoring Algorithm

The system uses a **weighted scoring mechanism** that adapts based on user priority:

#### 1. **Priority-Based Weights**
```python
if priority == "cost":
    weights = {"cost": 0.5, "speed": 0.2, "capability": 0.3}
elif priority == "speed":
    weights = {"cost": 0.2, "speed": 0.5, "capability": 0.3}
elif priority == "intelligence":
    weights = {"cost": 0.1, "speed": 0.2, "capability": 0.7}
else:  # balanced
    weights = {"cost": 0.33, "speed": 0.33, "capability": 0.34}
```

#### 2. **Component Scores** (0-100 scale)

**Cost Score:**
```python
if user_budget >= llm_cost:
    cost_score = 100
else:
    cost_score = (user_budget / llm_cost) * 100
```

**Speed Score:**
```python
if user_latency == llm_latency:
    speed_score = 100
elif compatible:
    speed_score = 70
else:
    speed_score = 40
```

**Capability Score:**
```python
capability_score = llm.task_scores[user_task_type] * 100
```

#### 3. **Total Score**
```python
total_score = (weights["cost"] * cost_score + 
               weights["speed"] * speed_score + 
               weights["capability"] * capability_score)
```

#### 4. **Explanation Generation**
Automatically generates natural language explanation:
```
"GPT-4o-mini scores 92/100. It fits your $5 budget ($0.15 actual cost), 
excels at code generation tasks (0.88 capability score), supports 128k 
context window, and is available as a cloud API."
```

---

## üìä Dataset

### Knowledge Base Structure

The `knowledge_base.json` contains 20+ LLMs with the following schema:

```json
{
  "name": "string",              // Model name
  "provider": "string",          // OpenAI, Anthropic, Google, etc.
  "cost_input_per_1m": float,   // USD per 1M input tokens
  "cost_output_per_1m": float,  // USD per 1M output tokens
  "context_window": int,         // Maximum tokens (4096 to 2000000)
  "latency_class": "string",     // realtime | moderate | batch
  "deployment": ["string"],      // cloud | local | both
  "task_scores": {
    "code": float,               // 0.0 to 1.0
    "chat": float,
    "summarize": float,
    "analysis": float,
    "translation": float,
    "rag": float
  },
  "tags": ["string"],
  "link": "string"               // Documentation URL
}
```

### Included Models (20+)

| Model | Provider | Cost/1M | Context | Best For |
|---|---|---|---|---|
| GPT-4o | OpenAI | $5.00 | 128k | General, Multimodal |
| GPT-4o-mini | OpenAI | $0.15 | 128k | Cost-effective |
| Claude 3.5 Sonnet | Anthropic | $3.00 | 200k | Analysis, Long context |
| Claude 3 Haiku | Anthropic | $0.25 | 200k | Speed, Cost |
| Gemini 1.5 Pro | Google | $3.50 | 2M | Extreme context |
| Gemini 1.5 Flash | Google | $0.075 | 1M | Fast, Affordable |
| Llama 3.1 70B | Meta | $0.59 | 128k | Open-source |
| Llama 3.1 8B | Meta | $0.05 | 128k | Local deployment |
| DeepSeek Coder V2 | DeepSeek | $0.14 | 128k | Code generation |
| Mistral 7B | Mistral | $0.06 | 32k | Open-source |
| ... | ... | ... | ... | ... |

### Data Sources

- **Pricing:** [OpenRouter](https://openrouter.ai/models), [LiteLLM GitHub](https://github.com/BerriAI/litellm)
- **Performance:** [Artificial Analysis](https://artificialanalysis.ai), [HuggingFace Leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard)
- **Specifications:** Official provider documentation

---

## üß™ Testing

### Run Tests
```bash
cd tests
pytest
```

### Test Reports
Test results are saved in `test_reports/` directory.

---

## üö¢ Deployment

### Backend (FastAPI)

#### Option 1: Render.com
```bash
# render.yaml
services:
  - type: web
    name: llmmatch-backend
    env: python
    buildCommand: pip install -r requirements.txt
    startCommand: uvicorn main:app --host 0.0.0.0 --port $PORT
```

#### Option 2: Railway
```bash
# Railway auto-detects FastAPI
# Just connect your GitHub repo
```

### Frontend (React)

#### Vercel
```bash
cd frontend
npm run build
# Deploy dist/ folder to Vercel
```

#### Netlify
```bash
# Build command: npm run build
# Publish directory: dist
```

---

## ü§ù Contributing

We welcome contributions! Here's how to get started:

### 1. Fork the Repository
```bash
git clone https://github.com/YOUR_USERNAME/LLMFinder.git
cd LLMFinder
```

### 2. Create a Feature Branch
```bash
git checkout -b feature/your-feature-name
```

### 3. Make Changes
- Add new LLM models to `knowledge_base.json`
- Improve scoring algorithm in `scorer.py`
- Enhance UI components in `frontend/src/`

### 4. Test Your Changes
```bash
# Backend tests
cd backend
pytest

# Frontend tests
cd frontend
npm test
```

### 5. Submit Pull Request
```bash
git add .
git commit -m "Add: your feature description"
git push origin feature/your-feature-name
```

### Contribution Ideas
- ‚úÖ Add more LLM models to knowledge base
- ‚úÖ Implement real benchmark data scraping
- ‚úÖ Add user authentication & history
- ‚úÖ Create comparison mode (compare 2 models side-by-side)
- ‚úÖ Add cost calculator feature
- ‚úÖ Implement LLM API testing capability
- ‚úÖ Add MongoDB for user data persistence

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üë• Team

**KMIT ‚Äî Department of Computer Science and Engineering (AI&ML)**  
**IV B.Tech I Semester ¬∑ A.Y 2025-26**

- **G. Rohith** (23BD5A6601)
- **K. Vignesh** (23BD5A6602)
- **K. SaiChandu** (23BD5A6604)
- **V. Manikanta** (23BD5A6606)

**Institution:** Keshav Memorial Institute of Technology (KMIT)  
**Branch:** CSE (AI&ML) - A Section  
**Project Stage:** Stage 1

---

## üîó Links

- **GitHub Repository:** [github.com/manivuppala124/LLMFinder](https://github.com/manivuppala124/LLMFinder)
- **Live Demo:** [Coming Soon]
- **API Documentation:** `http://localhost:8000/docs` (when running locally)

---

## üìß Contact

For questions, suggestions, or collaboration opportunities:
- Open an [Issue](https://github.com/manivuppala124/LLMFinder/issues)
- Submit a [Pull Request](https://github.com/manivuppala124/LLMFinder/pulls)

---

## üôè Acknowledgments

- **OpenRouter** for comprehensive LLM pricing data
- **Artificial Analysis** for performance benchmarks
- **HuggingFace** for open LLM leaderboard
- **FastAPI** & **React** communities for excellent documentation

---

<div align="center">

**‚≠ê Star this repo if you find it useful! ‚≠ê**

Made with ‚ù§Ô∏è by KMIT CSE(AI&ML) Team

</div>
